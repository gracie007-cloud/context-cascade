# Skillâ†’Agentâ†’Command Architecture - Quick Reference

**Document Version**: 1.0.0  
**Purpose**: Fast lookup guide for architecture concepts  
**Audience**: Developers, architects, AI engineers  

---

## 1. What Is This Architecture?

A **three-layer plugin system** for AI-assisted software development:

```
COMMANDS (223)           User interface (slash commands)
    â†“ bind to
SKILLS (183)              Methodology layer (how to solve problems)
    â†“ delegate to
AGENTS (211)             Expertise layer (who solves them)
    â†“ coordinated by
MEMORY MCP + HOOKS       Persistence & automation
```

**Key Innovation**: Theater detection via 6-agent Byzantine consensus validates real implementation vs fake.

---

## 2. Three Layers Explained

### Layer 1: SKILLS (93 total)

**What**: High-level frameworks for solving specific problems  
**Where**: `skills/` directory  
**Format**: Markdown with YAML frontmatter (`SKILL.md`)

**Key Skills**:
- `feature-dev-complete` - 12-stage feature development
- `research-driven-planning` - Loop 1: Planning with risk analysis
- `parallel-swarm-implementation` - Loop 2: Multi-agent execution
- `cicd-intelligent-recovery` - Loop 3: Quality & failure recovery
- `code-review-assistant` - Multi-agent PR reviews
- `theater-detection-audit` - 6-agent consensus validation
- `agent-creator` - 4-phase SOP for creating agents

**How to Find Skills**:
```bash
# Central registry
docs/MASTER-SKILLS-INDEX.md       # All 93 skills
skills/THREE-LOOP-INTEGRATION-*.md  # Three-loop architecture
skills/CREATION_SUMMARY.md          # Recent additions
```

### Layer 2: AGENTS (131 total)

**What**: Specialized AI agents with distinct expertise  
**Where**: `agents/` directory  
**Format**: Markdown with YAML frontmatter (`{agent}.md`)

**Agent Categories**:
| Category | Count | Examples |
|----------|-------|----------|
| Core Development | 8 | coder, reviewer, tester, researcher, planner |
| Testing & Validation | 9 | e2e-testing, security-testing, perf-testing |
| Frontend | 6 | react-dev, vue-dev, ui-builder |
| Database | 7 | db-design, query-optimizer, cache-strategist |
| Coordination | 15 | hierarchical, mesh, adaptive, byzantine |
| GitHub | 9 | pr-manager, release-manager, issue-tracker |
| Specialized | 12+ | backend-dev, ml-developer, cicd-engineer |

**5 Specialist Types** (use these, NOT "general-purpose"):
- `researcher` - Analyze, research, investigate
- `coder` - Build, implement, create, fix
- `analyst` - Review, test, audit, validate
- `optimizer` - Optimize, improve, tune, benchmark
- `coordinator` - Orchestrate, coordinate, manage, delegate

### Layer 3: COMMANDS (224 total)

**What**: User-facing slash commands  
**Where**: `commands/` directory  
**Format**: Markdown with YAML frontmatter  

**Command Categories** (MECE):
| Domain | Count |
|--------|-------|
| Development Workflow | 67 |
| Quality & Validation | 29 |
| Agent Lifecycle | 18 |
| Memory & State | 18 |
| Monitoring & Telemetry | 18 |
| Performance & Optimization | 18 |
| Integration & External | 21 |
| Research & Analysis | 20 |
| Automation & Hooks | 22 |
| Core Infrastructure | 3 |

**Essential Commands**:
- `/build-feature` - 12-stage feature development
- `/review-pr` - Multi-agent PR review
- `/fix-bug` - Smart bug fixing with root cause analysis
- `/quick-check` - Lightning-fast quality check
- `/sparc` - SPARC methodology execution

---

## 3. How Data Flows Through Layers

### Simple Flow: Command â†’ Skill â†’ Agents

```
User Input:
  /build-feature "user authentication"
         â†“
Parse YAML frontmatter:
  name: build-feature
  binding: skill:feature-dev-complete
         â†“
Load Skill: feature-dev-complete
  agents: [researcher, coder, tester, analyst, optimizer, coordinator]
  12 phases defined
         â†“
Spawn Agents (Claude Code Task tool):
  Task("researcher", "Phase 1: Research", "researcher")
  Task("coder", "Phase 3: Design", "coder")
  Task("coder", "Phase 5: Implement", "coder")
  ... (all in one message for parallelism)
         â†“
Pre-Hooks Execute:
  - Auto-assign agents by file type
  - Validate commands
  - Load context
         â†“
Agents Execute Skill Phases (parallel):
  Each agent runs its phases, stores results in memory
         â†“
Post-Hooks Execute:
  - Format code
  - Train neural patterns
  - Update memory
  - Track metrics
         â†“
User Gets Output:
  âœ… Feature complete, tests passing, PR ready
```

### Parallel Execution: Multi-Agent Review

```
/review-pr 123
         â†“
5 Agents Spawn Simultaneously:
  Task(analyst, "Security review", "analyst")
  Task(optimizer, "Performance review", "optimizer")
  Task(analyst, "Style review", "analyst")
  Task(analyst, "Test review", "analyst")
  Task(analyst, "Documentation review", "analyst")
         â†“
All 4 Execute in Parallel:
  Security â†’ 95/100
  Performance â†’ 88/100
  Style â†’ 90/100
  Tests â†’ 82/100
  Documentation â†’ 85/100
         â†“
Adaptive Coordinator Aggregates:
  Final Score: 88/100
  Decision: APPROVE
  Post comment with all findings
```

---

## 4. Memory MCP Integration

### Pattern: WHO/WHEN/PROJECT/WHY Tagging

Every memory write includes metadata:

```javascript
memory_store(
  key: "swarm/coder/implementation",
  value: { code, decisions, ... },
  tags: {
    WHO: {
      agent: "coder",
      category: "code-quality",
      capabilities: ["code-gen", "optimization"]
    },
    WHEN: {
      iso: "2025-11-06T10:30:00Z",
      unix: 1730875800,
      readable: "Nov 6, 2025 10:30"
    },
    PROJECT: "user-authentication",
    WHY: "implementation"  // implementation|bugfix|refactor|testing|documentation|analysis|planning|research
  }
)
```

### Memory Retrieval: Semantic Search

```javascript
memory_search(
  pattern: "swarm/*/auth*",
  query: "JWT token refresh strategy"
) 
â†’ Returns top 5-20 semantic matches ranked by relevance
```

### Retention Tiers

- **24 hours** - Current session context, active decisions
- **7 days** - Completed features, session summaries, patterns
- **30+ days** - Historical failures, architecture decisions, lessons learned

---

## 5. Three-Loop Integration

### Loop 1: Planning (research-driven-planning)

```
Input: User specification
       â†“
Step 1: Research (Gemini Search)
        Evidence-based findings
       â†“
Step 2: Planning (MECE breakdown)
        Task division
       â†“
Step 3: Pre-Mortem (5x risk analysis)
        Identify risks & mitigation
       â†“
Output: loop1-planning-package.json
        Memory: integration/loop1-to-loop2
```

### Loop 2: Implementation (parallel-swarm-implementation)

```
Input: Planning package from Loop 1
       â†“
Step 1: Discovery & Initialization
Step 2: MECE task division
Step 3: Multi-agent swarm deployment
Step 4: Theater detection (6-agent consensus)
Step 5: Integration & validation
       â†“
Output: loop2-delivery-package.json
        (code, tests, theater audit, metrics)
        Memory: integration/loop2-to-loop3
```

### Loop 3: CI/CD Quality (cicd-intelligent-recovery)

```
Input: Delivery package from Loop 2
       â†“
Step 1: GitHub hooks trigger
Step 2: Test failures analysis
Step 3: Root cause detection
Step 4: Intelligent fixes (Codex)
Step 5: Validation re-testing
       â†“
Output: loop3-failure-patterns.json
        (what failed, why, prevention strategies)
        Memory: integration/loop3-feedback
        
        â†“ FEEDBACK
        
Next iteration's Loop 1 loads historical failures
        â†“
Better planning due to real failure data
        â†“
Better implementation
        â†“
Better quality
```

---

## 6. Golden Rules & Best Practices

### GOLDEN RULE
```
1 MESSAGE = ALL RELATED OPERATIONS

Mandatory patterns:
- TodoWrite: Batch ALL todos in ONE call (5-10+ minimum)
- Task Tool: Spawn ALL agents in ONE message
- File Ops: Batch ALL reads/writes in ONE message
- Bash Cmds: Batch ALL terminal ops in ONE message
- Memory Ops: Batch ALL store/retrieve in ONE message
```

### Agent Selection Decision Tree

```
User says "analyze"     â†’ researcher
User says "build"       â†’ coder
User says "review"      â†’ analyst
User says "optimize"    â†’ optimizer
User says "manage"      â†’ coordinator

WRONG: "general-purpose", "developer", "agent"
RIGHT: "researcher", "coder", "analyst", "optimizer", "coordinator"
```

### Access Control Rules

```
CODE QUALITY AGENTS (211):
â”œâ”€ coder, reviewer, tester, analyst, code-analyzer
â”œâ”€ functionality-audit, theater-detection-audit
â”œâ”€ production-validator, sparc-coder, backend-dev
â”œâ”€ mobile-dev, ml-developer, base-template-generator
â””â”€ code-review-swarm
Can Access: memory-mcp, connascence-analyzer, claude-flow

PLANNING AGENTS (211):
â”œâ”€ planner, researcher, system-architect, specification
â”œâ”€ pseudocode, architecture, refinement
â”œâ”€ hierarchical-coordinator, mesh-coordinator, adaptive-coordinator
â”œâ”€ byzantine-coordinator, raft-manager, gossip-coordinator
â””â”€ consensus-builder, crdt-synchronizer, quorum-manager, [more]
Can Access: memory-mcp, claude-flow (NO connascence-analyzer)
```

### File Organization

```
DO:
âœ… /src - Source code
âœ… /tests - Test files
âœ… /docs - Documentation
âœ… /config - Configuration
âœ… /scripts - Utility scripts

DON'T:
âŒ Save working files to root folder
âŒ Mix documentation and code
âŒ Put tests in source directories (separate /tests folder)
```

---

## 7. Directory Quick Navigation

```
C:\Users\17175\
â”œâ”€â”€ skills/                    # All 93 skills
â”‚   â”œâ”€â”€ MASTER-SKILLS-INDEX.md    # Registry
â”‚   â”œâ”€â”€ feature-dev-complete/
â”‚   â”œâ”€â”€ when-*/ (trigger-based skills)
â”‚   â””â”€â”€ [90+ more skills]
â”‚
â”œâ”€â”€ .claude-code/skills/       # Additional skills
â”‚   â”œâ”€â”€ advanced-coordination/
â”‚   â”œâ”€â”€ agent-creation/
â”‚   â””â”€â”€ utilities/
â”‚
â”œâ”€â”€ agents/                    # All 211 agents
â”‚   â”œâ”€â”€ registry.json             # Central registry
â”‚   â”œâ”€â”€ core/                     # 8 core agents
â”‚   â”œâ”€â”€ frontend/                 # 6 frontend agents
â”‚   â”œâ”€â”€ database/                 # 7 database agents
â”‚   â”œâ”€â”€ testing/                  # 9 testing agents
â”‚   â”œâ”€â”€ swarm/                    # 15 coordination agents
â”‚   â””â”€â”€ [15+ more categories]
â”‚
â”œâ”€â”€ commands/                  # All 223 commands
â”‚   â”œâ”€â”€ README.md                 # Registry
â”‚   â”œâ”€â”€ essential-commands/       # 10 core commands
â”‚   â”œâ”€â”€ sparc/                    # 31 SPARC commands
â”‚   â”œâ”€â”€ agent-commands/           # 18 agent lifecycle
â”‚   â”œâ”€â”€ audit-commands/           # 29 quality commands
â”‚   â”œâ”€â”€ github/                   # 21 GitHub commands
â”‚   â””â”€â”€ [9+ more categories]
â”‚
â”œâ”€â”€ .claude/                   # Configuration
â”‚   â”œâ”€â”€ settings.json             # Hooks, permissions
â”‚   â”œâ”€â”€ sparc-modes.json
â”‚   â”œâ”€â”€ plugins/
â”‚   â””â”€â”€ [other config]
â”‚
â”œâ”€â”€ .mcp.json                  # MCP server config
â”‚   â””â”€â”€ 3 servers: claude-flow (required), ruv-swarm, flow-nexus
â”‚
â”œâ”€â”€ hooks/12fa/                # Integration hooks
â”‚   â””â”€â”€ memory-mcp-tagging-protocol.js
â”‚
â”œâ”€â”€ CLAUDE.md                  # PROJECT INSTRUCTIONS
â”‚   â””â”€â”€ Read for core rules & patterns
â”‚
â””â”€â”€ docs/                      # Documentation
    â”œâ”€â”€ SKILL-AGENT-COMMAND-ARCHITECTURE.md    â† Full reference
    â”œâ”€â”€ ARCHITECTURE-VISUAL-REFERENCE.md        â† Diagrams
    â”œâ”€â”€ MASTER-SKILLS-INDEX.md
    â”œâ”€â”€ MASTER-COMMAND-INDEX.md
    â””â”€â”€ [100+ other docs]
```

---

## 8. Common Tasks Quick Reference

### I want to create a new skill

1. Identify trigger conditions (when to use)
2. Define primary agents (who executes)
3. Design 7-12 phases with objectives
4. Document memory patterns (data storage)
5. Create YAML frontmatter in `skills/{name}/SKILL.md`
6. Add to `skills/MASTER-SKILLS-INDEX.md`
7. Register in memory namespace

**Reference**: `skills/agent-creator/SKILL.md` (4-phase methodology)

### I want to create a new agent

1. Define core identity and expertise domains
2. List 5+ capabilities specific to agent
3. Document decision frameworks (how agent decides)
4. Define quality standards (output validation)
5. Create file in `agents/{category}/{agent}.md` with YAML
6. Add to `agents/registry.json`
7. Assign MCP server access (control matrix)

**Reference**: `agents/core/coder.md` (example agent definition)

### I want to create a new command

1. Identify skill binding (which skill executes)
2. Document exact usage syntax and parameters
3. Explain multi-stage workflow
4. Provide 3-5 usage examples
5. Create file in `commands/{category}/{command}.md` with YAML
6. Add to `commands/README.md`
7. Test command â†’ skill â†’ agent flow

**Reference**: `commands/essential-commands/review-pr.md` (example)

### I want to integrate with MCP

1. Update `.mcp.json` to enable server
2. Add MCP tools to agent registry (capabilities)
3. Configure access control (which agents can use)
4. Update memory patterns (data storage keys)
5. Document in skill/agent/command frontmatter
6. Test in isolation first

**Reference**: `.mcp.json` (MCP configuration), `hooks/12fa/memory-mcp-tagging-protocol.js`

### I want to use the architecture

Follow the **GOLDEN RULE**:
```javascript
// Single message spawns ALL agents and operations
[Parallel Execution]:
  Task("Researcher", "Analyze API requirements", "researcher")
  Task("Backend Dev", "Implement endpoints", "coder")
  Task("Database Architect", "Design schema", "coder")
  Task("Test Engineer", "Write tests", "analyst")
  Task("Security Auditor", "Review security", "analyst")
  Task("Reviewer", "Code review", "analyst")
  Task("Coordinator", "Orchestrate workflow", "coordinator")
  
  TodoWrite { todos: [...all todos in ONE call...] }
  
  // File operations batched
  Write "file1.js"
  Write "file2.js"
  Write "file3.js"
```

---

## 9. Important Files to Know

```
CONFIGURATION:
â”œâ”€ CLAUDE.md                 # Core project rules (READ THIS FIRST)
â”œâ”€ .claude/settings.json     # Hooks & permissions
â”œâ”€ .mcp.json                 # MCP servers
â””â”€ agents/registry.json      # Agent definitions

REGISTRIES:
â”œâ”€ skills/MASTER-SKILLS-INDEX.md       # All 93 skills
â”œâ”€ commands/README.md                   # All 223 commands
â””â”€ agents/registry.json                 # All 211 agents

ARCHITECTURE DOCS:
â”œâ”€ docs/SKILL-AGENT-COMMAND-ARCHITECTURE.md      # Full reference
â”œâ”€ docs/ARCHITECTURE-VISUAL-REFERENCE.md         # Diagrams
â”œâ”€ docs/ARCHITECTURE-QUICK-REFERENCE.md          # This file
â”œâ”€ skills/THREE-LOOP-INTEGRATION-ARCHITECTURE.md # Loop details
â””â”€ docs/MASTER-COMMAND-INDEX.md                  # Command details

INTEGRATION:
â”œâ”€ hooks/12fa/memory-mcp-tagging-protocol.js     # Memory tagging
â””â”€ .claude-flow/                                  # Flow Nexus config
```

---

## 10. Theater Detection - Key Concept

**Problem**: How to verify code actually works (not just looks good)?

**Solution**: 6-Agent Byzantine Consensus

```
6 agents test implementation independently:
1. Sandbox execution test      â†’ âœ… Runs without errors
2. Coverage validation         â†’ âœ… 95% coverage
3. Mock detection             â†’ âœ… No fake implementations
4. Integration test           â†’ âœ… All parts work together
5. Performance benchmark      â†’ âœ… Performance acceptable
6. Security validation        â†’ âœ… No vulnerabilities

CONSENSUS (â‰¥5/6 pass):
âœ… REAL IMPLEMENTATION

CONSENSUS (â‰¤4/6 pass):
âŒ THEATER DETECTED - Needs investigation
```

**Skill**: `theater-detection-audit`  
**Reference**: `commands/audit-commands/theater-detect.md`

---

## 11. Memory Storage Examples

### Example 1: Store Implementation Decision

```javascript
memory_store(
  key: "swarm/feature-dev/auth-jwt-decision",
  value: {
    decision: "Use JWT with refresh tokens",
    rationale: "Stateless, scalable, industry standard",
    tradeoffs: ["need refresh token rotation", "token expiry handling"],
    alternatives: ["session-based", "OAuth 2.0"],
    rejected: ["session-based due to database dependency"]
  },
  tags: {
    WHO: { agent: "researcher", category: "planning" },
    WHEN: { iso: "2025-11-06T10:30:00Z" },
    PROJECT: "user-authentication",
    WHY: "planning"
  }
)
```

### Example 2: Retrieve Similar Decisions

```javascript
memory_search(
  pattern: "swarm/*/auth*",
  query: "JWT authentication implementation strategy"
)
â†’ Returns: Top 5-20 semantic matches with ranking
   1. Previous JWT decision (95% match)
   2. OAuth2 vs JWT comparison (87% match)
   3. Token refresh patterns (82% match)
   ...
```

### Example 3: Load Historical Failures

```javascript
memory_search(
  pattern: "integration/loop3-feedback/*",
  query: "async race condition bugs"
)
â†’ Returns: All documented async failures
   Pattern: race-condition
   Frequency: 3 occurrences
   Root causes: concurrent requests, shared state
   Prevention: mutex locks, request queueing
```

---

## 12. Execution Examples

### Example 1: Build Feature (Simple Flow)

```bash
/build-feature "user authentication with JWT"

Expected Output:
âœ… Research: Best practices analyzed
âœ… Architecture: Design documented
âœ… Implementation: Code written
âœ… Tests: 95% coverage
âœ… Security: No vulnerabilities
âœ… Optimization: Performance validated
âœ… Documentation: Complete
âœ… PR: Created and ready to merge
```

### Example 2: Review PR (Parallel Execution)

```bash
/review-pr 123

Expected Output:
ğŸ¤– Code Review Complete: PR #123
Overall Score: 87/100
  Security: 95/100 âœ…
  Performance: 88/100 âœ…
  Style: 90/100 âœ…
  Tests: 82/100 âœ…
  Docs: 85/100 âœ…
Merge Ready: âœ… Yes
```

### Example 3: Theater Detection (Consensus)

```bash
/quick-check src/auth.js

Expected Output:
6-Agent Byzantine Consensus:
  Agent 1 (Sandbox):      âœ… Real
  Agent 2 (Coverage):     âœ… 95%
  Agent 3 (Mocks):        âœ… None detected
  Agent 4 (Integration):  âœ… Works
  Agent 5 (Performance):  âœ… Fast
  Agent 6 (Security):     âœ… Secure

CONSENSUS (6/6 pass):
âœ… REAL IMPLEMENTATION (100% confidence)
```

---

## 13. Troubleshooting Quick Guide

| Issue | Solution |
|-------|----------|
| Command won't execute | Check skill binding in command YAML |
| Agent seems confused | Verify agent has required MCP server access |
| Memory operation fails | Ensure WHO/WHEN/PROJECT/WHY tags included |
| Agents not coordinating | Check coordination hooks in settings.json |
| Theater detection fails | May indicate real implementation issue |
| Performance problems | Run `/profiler-start` then `/profiler-stop` |
| Test coverage low | Review `functionality-audit` results |
| Slow multi-agent execution | Verify parallel Task tool usage (1 message) |

---

## 14. Key Metrics & Thresholds

| Metric | Threshold | Agent |
|--------|-----------|-------|
| Code Quality | â‰¥80/100 | code-analyzer |
| Test Coverage | â‰¥90% | tester |
| Theater Detection | â‰¥5/6 agents pass | analyst |
| Security Issues | 0 critical | security-tester |
| Performance | Within SLA | optimizer |
| Documentation | â‰¥90% complete | system-architect |
| Cyclomatic Complexity | <10 | code-analyzer |
| Function Length | <50 lines | code-analyzer |

---

## 15. Recommended Reading Order

1. **Start here**: `CLAUDE.md` (project rules)
2. **Understand architecture**: `docs/SKILL-AGENT-COMMAND-ARCHITECTURE.md`
3. **See visuals**: `docs/ARCHITECTURE-VISUAL-REFERENCE.md`
4. **Find skills**: `skills/MASTER-SKILLS-INDEX.md`
5. **Find commands**: `commands/README.md`
6. **Find agents**: `agents/registry.json`
7. **Understand loops**: `skills/THREE-LOOP-INTEGRATION-ARCHITECTURE.md`
8. **Deep dive**: Specific skill/agent/command docs as needed

---

## Summary

This is a **three-layer architecture** where:

```
COMMANDS (user interface)
    â†“ bind to
SKILLS (methodology)
    â†“ delegate to
AGENTS (expertise)
    â†“ coordinated via
MEMORY + HOOKS (persistence & automation)
```

**Key principles**:
- âœ… Clear separation of concerns
- âœ… 131 specialized agents with distinct expertise
- âœ… 93 reusable skills covering all domains
- âœ… 223 commands for granular control
- âœ… Persistent memory with semantic search
- âœ… Theater detection via Byzantine consensus
- âœ… Three-loop feedback for continuous improvement
- âœ… Parallel execution with adaptive coordination

**Central command**: 
```
GOLDEN RULE: 1 MESSAGE = ALL RELATED OPERATIONS
```

Use Claude Code's Task tool to spawn agents, batch all operations together, and leverage memory for cross-session learning.
